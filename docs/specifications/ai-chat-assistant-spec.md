# ğŸ¤– AI CHAT ASSISTANT - Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞĞ• Ğ—ĞĞ”ĞĞĞ˜Ğ•

## ğŸ“‹ **ĞœĞ•Ğ¢ĞĞ”ĞĞĞĞ«Ğ•**

| ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|----------|----------|
| **ĞŸÑ€Ğ¾ĞµĞºÑ‚** | AI Video Interview Platform |
| **ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚** | AI Chat Assistant |
| **Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ** | ğŸ”´ NOT STARTED |
| **ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚** | ğŸŸ¡ MEDIUM (Ğ¿Ğ¾ÑĞ»Ğµ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ core Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²) |
| **Ğ¦ĞµĞ»ÑŒ** | ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ AI integration + ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ UX |
| **Ğ‘ÑĞ´Ğ¶ĞµÑ‚** | $0 (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ API) |
| **Ğ’ĞµÑ€ÑĞ¸Ñ** | 1.0 |
| **Ğ”Ğ°Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ** | 2025-09-30 |

---

## ğŸ¯ **Ğ¦Ğ•Ğ›Ğ˜ Ğ˜ Ğ—ĞĞ”ĞĞ§Ğ˜**

### **ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ†ĞµĞ»ÑŒ:**
Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ AI-powered chat assistant Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ Ğ¿Ğ¾ÑĞµÑ‚Ğ¸Ñ‚ĞµĞ»ÑĞ¼ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… LLM APIs.

### **ĞĞ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ğµ Ñ†ĞµĞ»Ğ¸:**
- âœ… Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ LLM (Gemini, Groq)
- âœ… ĞĞ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ RAG (Retrieval Augmented Generation)
- âœ… ĞŸĞ¾Ğ½ÑÑ‚ÑŒ streaming responses Ğ² real-time
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ fallback Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ´Ğ»Ñ AI services
- âœ… ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° prompt engineering

### **Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ñ†ĞµĞ»Ğ¸:**
- âœ… Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ onboarding Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ¾ÑĞµÑ‚Ğ¸Ñ‚ĞµĞ»ĞµĞ¹
- âœ… ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° FAQ
- âœ… ĞšĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ leads Ğ´Ğ»Ñ demo
- âœ… ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ AI capabilities Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹

---

## ğŸ—ï¸ **ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ**

### **Microservice Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js)                        â”‚
â”‚                     Chat Widget UI                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/SSE
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API GATEWAY (NestJS)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Proxy: /ai/* â†’ AI Service                         â”‚    â”‚
â”‚  â”‚  Auth: JWT validation                              â”‚    â”‚
â”‚  â”‚  Rate Limiting                                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Internal HTTP
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI SERVICE (NestJS) - Port 3006                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           AI Chat Module                             â”‚  â”‚
â”‚  â”‚  - Chat Controller                                   â”‚  â”‚
â”‚  â”‚  - Chat Service                                      â”‚  â”‚
â”‚  â”‚  - Provider Factory (Gemini â†’ Groq fallback)        â”‚  â”‚
â”‚  â”‚  - RAG Context Builder                               â”‚  â”‚
â”‚  â”‚  - Conversation Manager                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  Future AI Features:                                         â”‚
â”‚  - Whisper Transcription Module                             â”‚
â”‚  - Interview Analysis Module                                â”‚
â”‚  - Candidate Evaluation Module                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                       â”‚
             â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Gemini API     â”‚      â”‚  Groq API      â”‚
    â”‚ (PRIMARY)      â”‚      â”‚  (FALLBACK)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                       â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Redis Cache          â”‚
             â”‚   - Conversations      â”‚
             â”‚   - Context            â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Why Separate Microservice:**

**âœ… Advantages:**
1. **Isolation:** AI workload Ğ½Ğµ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° API Gateway performance
2. **Scaling:** ĞœĞ¾Ğ¶Ğ½Ğ¾ scale AI service independently
3. **Technology:** AI dependencies Ğ¸Ğ·Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹
4. **Future-proof:** Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ hub Ğ´Ğ»Ñ Ğ²ÑĞµÑ… AI features
5. **Monitoring:** ĞÑ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ cost tracking
6. **Development:** ĞœĞ¾Ğ¶Ğ½Ğ¾ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
7. **Deployment:** Independent deployment cycles

**Service Communication:**
- API Gateway â†’ AI Service: Internal HTTP (service-to-service)
- External clients â†’ API Gateway â†’ AI Service (proxy pattern)
- Auth handled by API Gateway, AI Service trusts gateway

### **AI Providers Strategy:**

#### **1ï¸âƒ£ Google Gemini (PRIMARY)**
```yaml
Provider: Google AI Studio
Model: gemini-1.5-flash
Library: @google/generative-ai
Cost: FREE
Limits:
  requests_per_minute: 60
  requests_per_day: 1500
  tokens_per_day: 1000000
API_Key: https://aistudio.google.com/app/apikey
```

**ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Gemini:**
- Ğ›ÑƒÑ‡ÑˆĞµĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ€ĞµĞ´Ğ¸ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ…
- Ğ©ĞµĞ´Ñ€Ñ‹Ğµ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ dev/testing
- ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°
- Streaming support
- Google reliability

#### **2ï¸âƒ£ Groq (FALLBACK)**
```yaml
Provider: Groq Cloud
Model: llama-3.1-8b-instant
Library: openai (compatible)
Cost: FREE
Limits:
  requests_per_day: 14400
  tokens_per_minute: 7000
API_Key: https://console.groq.com/
```

**ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Groq:**
- Ğ¡Ğ°Ğ¼Ñ‹Ğ¹ Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ streaming (500+ tokens/sec)
- OpenAI-compatible API
- Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğµ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹
- ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ fallback option

### **Fallback Strategy:**
```typescript
Request Flow:
1. Try Gemini (primary)
   â†“ If quota exceeded or error
2. Try Groq (fallback)
   â†“ If both fail
3. Return cached response or error message
```

---

## ğŸ“¦ **ĞšĞĞœĞŸĞĞĞ•ĞĞ¢Ğ«**

### **1. AI Service (NEW Microservice)**

**Location:** `apps/ai-service/`

**Port:** `3006`

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°:**
```
apps/ai-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                      # Service entry point
â”‚   â”œâ”€â”€ app.module.ts
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ ai.config.ts             # AI providers config
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ chat.module.ts
â”‚   â”‚   â”œâ”€â”€ chat.controller.ts       # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ chat.service.ts          # Business logic
â”‚   â”‚   â”œâ”€â”€ conversation.service.ts  # Context management
â”‚   â”‚   â””â”€â”€ dto/
â”‚   â”‚       â”œâ”€â”€ chat-message.dto.ts
â”‚   â”‚       â””â”€â”€ chat-response.dto.ts
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base.provider.interface.ts
â”‚   â”‚   â”œâ”€â”€ gemini.provider.ts       # PRIMARY
â”‚   â”‚   â”œâ”€â”€ groq.provider.ts         # FALLBACK
â”‚   â”‚   â””â”€â”€ provider.factory.ts
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ document-loader.service.ts
â”‚   â”‚   â”œâ”€â”€ context-builder.service.ts
â”‚   â”‚   â””â”€â”€ embeddings.service.ts (optional)
â”‚   â”œâ”€â”€ health/
â”‚   â”‚   â””â”€â”€ health.controller.ts     # Health checks
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ logger/
â”‚       â”œâ”€â”€ metrics/
â”‚       â””â”€â”€ tracing/
â”œâ”€â”€ test/
â”œâ”€â”€ tsconfig.json
â””â”€â”€ package.json
```

**Endpoints:**
```
POST   /chat/message            # Send message, get response
GET    /chat/stream             # SSE streaming
GET    /chat/history/:id        # Conversation history
DELETE /chat/clear/:id          # Clear conversation
GET    /health                  # Service health
GET    /health/providers        # Providers status (Gemini, Groq)
GET    /metrics                 # Prometheus metrics
```

### **2. API Gateway (Proxy Layer)**

**ĞĞ¾Ğ²Ñ‹Ğµ Ñ€Ğ¾ÑƒÑ‚Ñ‹:**
```typescript
// apps/api-gateway/src/proxy/ai-proxy.controller.ts

@Controller('ai')
export class AIProxyController {
  constructor(private httpService: HttpService) {}
  
  // Proxy all /ai/* requests to AI Service
  @All('*')
  async proxyToAIService(
    @Req() req: Request,
    @Res() res: Response
  ) {
    const aiServiceUrl = process.env.AI_SERVICE_URL || 'http://localhost:3006';
    // Forward request with auth context
    // Handle streaming responses
  }
}
```

**ĞÑ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ:**
- Auth validation (JWT)
- Rate limiting
- Request proxying
- Load balancing (future)

### **3. Frontend: Chat Widget**

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°:**
```
apps/web/components/ai-chat/
â”œâ”€â”€ chat-widget.tsx              # Main component
â”œâ”€â”€ chat-button.tsx              # Floating button
â”œâ”€â”€ chat-window.tsx              # Chat interface
â”œâ”€â”€ message-list.tsx             # Messages display
â”œâ”€â”€ message-input.tsx            # User input
â”œâ”€â”€ typing-indicator.tsx         # AI thinking animation
â””â”€â”€ hooks/
    â””â”€â”€ use-chat.ts              # Chat state management
```

**API Calls:**
```typescript
// Frontend Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· API Gateway
const API_BASE = 'http://localhost:3002';

// API Gateway Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ° AI Service
POST ${API_BASE}/ai/chat/message
  â†“ Proxy
POST http://localhost:3006/chat/message
```

---

## ğŸ”§ **Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ Ğ¡Ğ¢Ğ•Ğš**

### **Dependencies:**

```json
{
  "dependencies": {
    "@google/generative-ai": "^0.21.0",
    "openai": "^4.67.0",
    "ioredis": "^5.4.1"
  }
}
```

### **Configuration:**

```bash
# .env for AI Service
GEMINI_API_KEY=your_free_gemini_key
GROQ_API_KEY=your_free_groq_key

AI_CHAT_ENABLED=true
AI_PRIMARY_PROVIDER=gemini
AI_FALLBACK_PROVIDER=groq
AI_MAX_TOKENS=500
AI_TEMPERATURE=0.7

# Rate Limiting
AI_RATE_LIMIT_MESSAGES=20
AI_RATE_LIMIT_CONVERSATIONS=5

# Service Configuration
AI_SERVICE_PORT=3006
AI_SERVICE_HOST=0.0.0.0

# Redis for conversation context
REDIS_HOST=localhost
REDIS_PORT=6379

# .env for API Gateway
AI_SERVICE_URL=http://localhost:3006
AI_SERVICE_TIMEOUT=30000
```

### **Docker Compose:**

```yaml
# Add to docker-compose.yml

services:
  # ... existing services ...
  
  ai-service:
    build:
      context: .
      dockerfile: apps/ai-service/Dockerfile
    ports:
      - "3006:3006"
    environment:
      - NODE_ENV=development
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    networks:
      - ai-interview-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3006/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

---

## ğŸ¨ **UI/UX Ğ”Ğ˜Ğ—ĞĞ™Ğ**

### **Floating Button (Minimized):**
```
Position: Bottom-right corner (20px from edges)
Size: 64px Ã— 64px
Style: Gradient background, pulse animation
Icon: ğŸ’¬ Ğ¸Ğ»Ğ¸ custom AI icon
```

### **Chat Window (Expanded):**
```
Size: 400px Ã— 600px
Style: Glass morphism
Position: Above floating button
Components:
  - Header (title + close button)
  - Messages area (scrollable)
  - Input area (textarea + send)
```

### **Message Styles:**
```
User Messages: Right-aligned, gradient background
AI Messages: Left-aligned, white background
Streaming: Typing cursor animation
```

---

## ğŸ”„ **Ğ¤Ğ£ĞĞšĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞĞ¡Ğ¢Ğ¬**

### **MVP (Phase 1):**

1. **Basic Q&A**
   - ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğµ
   - RAG Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
   - Context-aware responses

2. **FAQ Automation**
   - ĞĞ²Ñ‚Ğ¾Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹
   - Ğ¦ĞµĞ½Ñ‹, features, Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸

3. **Demo Qualification**
   - Ğ¡Ğ±Ğ¾Ñ€ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ½Ğ¾ÑÑ‚ÑÑ…
   - ĞĞ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ„Ğ¾Ñ€Ğ¼Ñƒ demo

4. **Streaming Responses**
   - Real-time typing animation
   - SSE for smooth UX

### **Advanced (Phase 2+):**

5. **Multi-turn Conversations**
   - Context ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Redis
   - Memory across messages

6. **Analytics**
   - Track user questions
   - Measure satisfaction
   - Conversion funnel

7. **Personalization**
   - ĞĞ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´ Ñ€Ğ¾Ğ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
   - Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹

---

## ğŸ“Š **ĞœĞĞĞ˜Ğ¢ĞĞ Ğ˜ĞĞ“**

### **Metrics:**
```
AI Service Metrics (port 3006/metrics):
- ai_service_response_time_seconds
- ai_service_tokens_used_total (by provider)
- ai_service_provider_errors_total
- ai_service_fallback_triggers_total
- ai_service_conversations_active
- ai_service_requests_total

Business Metrics:
- ai_chat_conversations_started_total
- ai_chat_messages_sent_total
- ai_chat_demo_requests_total
- ai_chat_user_satisfaction_avg

API Gateway Proxy Metrics:
- ai_proxy_requests_total
- ai_proxy_response_time_seconds
- ai_proxy_errors_total
```

### **Grafana Dashboard:**
```
ai-service-dashboard.json:
  Row 1: Service Health
    - AI Service status
    - Provider availability (Gemini, Groq)
    - Active connections
  
  Row 2: Performance
    - Response time (by provider)
    - Tokens usage
    - Fallback rate
  
  Row 3: Business Metrics
    - Conversations per hour
    - Messages per hour
    - Demo requests
```

---

## ğŸ§ª **Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•**

### **Unit Tests:**
```typescript
ai-chat.service.spec.ts
  âœ… Provider selection logic
  âœ… Fallback mechanism
  âœ… Error handling

gemini.provider.spec.ts
  âœ… API integration
  âœ… Streaming responses
  âœ… Error scenarios
```

### **Integration Tests:**
```typescript
ai-chat.e2e.spec.ts
  âœ… End-to-end chat flow
  âœ… SSE streaming
  âœ… Context persistence
  âœ… Rate limiting
```

---

## ğŸ“ˆ **Ğ­Ğ¢ĞĞŸĞ« Ğ ĞĞ—Ğ ĞĞ‘ĞĞ¢ĞšĞ˜**

### **Phase 0: Prerequisites (BEFORE START)**
```
Status: ğŸ”´ WAITING

Checklist:
â–¡ Registration flow Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½
â–¡ User/Interview services ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹  
â–¡ API Gateway Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾
â–¡ Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ´Ğ»Ñ RAG
â–¡ Redis Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½
```

### **Phase 1: AI Service Setup (Week 1)**
```
Tasks:
â–¡ Create new NestJS app: apps/ai-service
â–¡ Setup project structure
â–¡ Configure Gemini provider
â–¡ Configure Groq provider  
â–¡ Implement fallback logic
â–¡ Basic chat endpoint
â–¡ RAG context builder
â–¡ Redis integration for conversations
â–¡ Health checks
â–¡ Unit tests

Deliverable: Standalone AI Service running on port 3006
```

### **Phase 1.5: API Gateway Proxy (2 days)**
```
Tasks:
â–¡ Create AI proxy controller in API Gateway
â–¡ Implement request forwarding
â–¡ Add auth middleware
â–¡ Add rate limiting
â–¡ Handle SSE streaming proxy
â–¡ Integration tests

Deliverable: API Gateway proxying to AI Service
```

### **Phase 2: Frontend MVP (Week 2)**
```
Tasks:
â–¡ Chat widget UI
â–¡ Floating button component
â–¡ Message components
â–¡ API integration
â–¡ State management
â–¡ Styling

Deliverable: Working chat widget
```

### **Phase 3: Streaming (Week 3)**
```
Tasks:
â–¡ SSE endpoint
â–¡ Frontend EventSource
â–¡ Typing animations
â–¡ Error handling

Deliverable: Real-time responses
```

### **Phase 4: Production Ready (Week 4+)**
```
Tasks:
â–¡ Analytics integration
â–¡ Monitoring setup
â–¡ Load testing
â–¡ Documentation
â–¡ Deployment

Deliverable: Production deployment
```

---

## ğŸ’° **COST ESTIMATION**

### **Development Time:**
```
AI Service Setup: 1 week
API Gateway Proxy: 2 days
Frontend MVP: 1 week
Streaming: 1 week
Polish & Deploy: 1 week

Total: ~4.5 weeks part-time
```

### **Infrastructure Cost:**
```
Gemini API: $0/month (free tier sufficient)
Groq API: $0/month (free tier sufficient)
Redis: $0 (already have)
Hosting: $0 (one more container)
Additional resources: Minimal (AI Service lightweight)

Total: $0/month during development ğŸ‰
```

### **Service Ports:**
```
API Gateway: 3002
User Service: 3003
Interview Service: 3004
Media Service: 3005
AI Service: 3006 â† NEW!
```

### **Production Scale (hypothetical):**
```
10K conversations/month:
  Gemini cost: ~$5-10/month
  Still cheaper than support team!
```

---

## ğŸ“š **Ğ”ĞĞšĞ£ĞœĞ•ĞĞ¢ĞĞ¦Ğ˜Ğ¯**

### **To Create:**
```
docs/user-guides/ai-chat-guide.md
  - ĞšĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ
  - ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²

docs/technical/ai-chat-architecture.md
  - ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°
  - API reference

docs/operations/ai-chat-monitoring.md
  - ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
  - Troubleshooting
```

---

## âœ… **SUCCESS CRITERIA**

### **Technical:**
```
âœ… Response time < 3s (p95)
âœ… Uptime > 99% (with fallback)
âœ… Error rate < 1%
âœ… Zero cost in dev phase
```

### **User Experience:**
```
âœ… ĞŸĞ¾Ğ½ÑÑ‚Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
âœ… Ğ ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
âœ… Smooth streaming
âœ… Mobile friendly
```

### **Learning Goals:**
```
âœ… LLM integration mastery
âœ… RAG implementation
âœ… Streaming patterns
âœ… Production AI deployment
```

---

## ğŸ”® **Ğ‘Ğ£Ğ”Ğ£Ğ©Ğ˜Ğ• Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞ˜Ğ¯**

### **Advanced Features:**
```
â–¡ Voice input (Web Speech API)
â–¡ Multi-language auto-detect
â–¡ Function calling (book demos, create interviews)
â–¡ Admin dashboard for analytics
â–¡ Custom fine-tuning
â–¡ Proactive suggestions
```

---

## ğŸ“ **Ğ—ĞĞœĞ•Ğ¢ĞšĞ˜**

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ:**
- **ĞÑ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸Ñ** = isolation, scalability, future-proof
- **Gemini primary** = Ğ»ÑƒÑ‡ÑˆĞµĞµ quality/cost ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ
- **Groq fallback** = fastest streaming, OpenAI-compatible
- **Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ API** = zero cost Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
- **RAG Ğ½Ğ° docs** = relevant context
- **Redis context** = stateful conversations
- **API Gateway proxy** = centralized auth + routing

**ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ½Ğ¾Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹:**
1. AI workload Ğ¸Ğ·Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ¾Ñ‚ critical gateway
2. ĞœĞ¾Ğ¶Ğ½Ğ¾ scale AI service Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾
3. Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ hub Ğ´Ğ»Ñ Ğ²ÑĞµÑ… AI features (chat, Whisper, analysis)
4. Ğ›ĞµĞ³Ñ‡Ğµ testing Ğ¸ deployment
5. Technology stack isolation

**Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚ Ğº Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ:**
ĞŸĞ¾ÑĞ»Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ registration flow Ğ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ core Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ².

---

**STATUS: ğŸ”´ READY FOR FUTURE IMPLEMENTATION**

**NEXT STEPS:**
1. Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚ÑŒ registration
2. Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
3. Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¢Ğ—
4. Start Phase 1
