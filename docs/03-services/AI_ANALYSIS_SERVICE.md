# AI Analysis Service

**Status:** ğŸ”´ Not Implemented  
**Port:** 3007  
**Technology Stack:** NestJS, TypeORM, PostgreSQL, Groq API, pgvector  
**Priority:** HIGH (Core value proposition)

---

## Overview

AI Analysis Service is responsible for analyzing candidate interview responses using LLM-based evaluation. It processes transcribed answers, extracts insights, and provides objective feedback using RAG (Retrieval-Augmented Generation) pattern.

**Key Capabilities:**
- Interview response analysis via LLM (LLama 3.3 70B)
- RAG-based contextual evaluation against job requirements
- Skills extraction and scoring
- Sentiment and communication analysis
- Comparative candidate ranking

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AI ANALYSIS SERVICE (3007)                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Kafka Consumer Layer                    â”‚   â”‚
â”‚  â”‚  - interview.completed events                        â”‚   â”‚
â”‚  â”‚  - transcription.ready events                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Application Layer (CQRS)                â”‚   â”‚
â”‚  â”‚  Commands:                    Queries:               â”‚   â”‚
â”‚  â”‚  - AnalyzeInterview           - GetAnalysisById      â”‚   â”‚
â”‚  â”‚  - GenerateFeedback           - GetCandidateScore    â”‚   â”‚
â”‚  â”‚  - ExtractSkills              - CompareĞ¡andidates    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              RAG Pipeline                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Embedding   â”‚â†’ â”‚  Vector     â”‚â†’ â”‚   LLM       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Generator   â”‚  â”‚  Search     â”‚  â”‚   Prompt    â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Infrastructure Layer                    â”‚   â”‚
â”‚  â”‚  - GroqService (LLM API)                            â”‚   â”‚
â”‚  â”‚  - EmbeddingService (text-embedding-3-small)        â”‚   â”‚
â”‚  â”‚  - VectorRepository (pgvector)                      â”‚   â”‚
â”‚  â”‚  - AnalysisRepository (TypeORM)                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
    PostgreSQL            Kafka              Groq API
   (+ pgvector)        (events)         (LLama 3.3 70B)
```

---

## Groq API Integration

### Selected Models

| Model | Purpose | Rate Limit (Free) |
|-------|---------|-------------------|
| **llama-3.3-70b-versatile** | Interview analysis, feedback generation | ~6000 tokens/min |
| **llama-3.1-8b-instant** | Quick scoring, simple evaluations | ~20000 tokens/min |

### Configuration

```yaml
# Environment Variables
GROQ_API_KEY=gsk_xxxxxxxxxxxx
GROQ_MODEL_PRIMARY=llama-3.3-70b-versatile
GROQ_MODEL_FAST=llama-3.1-8b-instant
GROQ_MAX_TOKENS=4096
GROQ_TEMPERATURE=0.3
```

### Rate Limiting Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Rate Limiter                           â”‚
â”‚                                                         â”‚
â”‚  Token Bucket Algorithm:                                â”‚
â”‚  - Bucket size: 6000 tokens                            â”‚
â”‚  - Refill rate: 6000 tokens/minute                     â”‚
â”‚  - Queue overflow: Redis queue for backpressure        â”‚
â”‚                                                         â”‚
â”‚  Retry Policy:                                          â”‚
â”‚  - Max retries: 3                                       â”‚
â”‚  - Backoff: exponential (1s, 2s, 4s)                   â”‚
â”‚  - On 429: queue and retry after rate limit reset      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## RAG Pipeline

### 1. Document Preparation (Job Requirements)

```
Job Description â†’ Chunking â†’ Embedding â†’ pgvector Storage

Chunk Strategy:
- Chunk size: 500 tokens
- Overlap: 50 tokens
- Metadata: section_type, importance_level
```

### 2. Query Flow (Candidate Response Analysis)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG Query Flow                            â”‚
â”‚                                                                  â”‚
â”‚  1. Transcription     2. Embedding      3. Vector Search         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "I have 5   â”‚ â”€â”€â–¶ â”‚ [0.12, 0.45 â”‚ â”€â–¶â”‚ SELECT * FROM       â”‚  â”‚
â”‚  â”‚ years of    â”‚     â”‚  0.78, ...]  â”‚   â”‚ embeddings          â”‚  â”‚
â”‚  â”‚ React..."   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ ORDER BY embedding   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚ <-> $1 LIMIT 5       â”‚  â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                   â”‚               â”‚
â”‚  4. Context Assembly              5. LLM Prompt                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Job Req: "5+ years   â”‚   â”€â”€â–¶  â”‚ System: You are an expert  â”‚ â”‚
â”‚  â”‚ React experience"    â”‚        â”‚ interviewer...             â”‚ â”‚
â”‚  â”‚                      â”‚        â”‚ Context: {job_requirements}â”‚ â”‚
â”‚  â”‚ Job Req: "TypeScript â”‚        â”‚ Response: {transcription}  â”‚ â”‚
â”‚  â”‚ proficiency"         â”‚        â”‚ Task: Evaluate...          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚               â”‚
â”‚                                                   â–¼               â”‚
â”‚                           6. Structured Output                   â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                           â”‚ {                                  â”‚ â”‚
â”‚                           â”‚   "score": 85,                     â”‚ â”‚
â”‚                           â”‚   "skills_matched": [...],         â”‚ â”‚
â”‚                           â”‚   "feedback": "...",               â”‚ â”‚
â”‚                           â”‚   "improvement_areas": [...]       â”‚ â”‚
â”‚                           â”‚ }                                  â”‚ â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Embedding Strategy

```yaml
# Using OpenAI embeddings (more stable) or local alternative
EMBEDDING_PROVIDER: openai  # or 'local'
EMBEDDING_MODEL: text-embedding-3-small
EMBEDDING_DIMENSIONS: 1536

# Alternative: Hugging Face local model
# EMBEDDING_MODEL: sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_DIMENSIONS: 384
```

---

## Kafka Integration

### Subscribed Topics

| Topic | Event | Action |
|-------|-------|--------|
| `interview-events` | `interview.completed` | Trigger analysis pipeline |
| `media-events` | `transcription.ready` | Process transcription |

### Published Topics

| Topic | Event | Trigger |
|-------|-------|---------|
| `analysis-events` | `analysis.completed` | After LLM evaluation |
| `analysis-events` | `analysis.failed` | On processing error |

### Event Schemas

**Incoming: interview.completed**
```json
{
  "eventId": "uuid",
  "eventType": "interview.completed",
  "timestamp": "2025-01-01T00:00:00Z",
  "data": {
    "interviewId": "uuid",
    "candidateId": "uuid",
    "templateId": "uuid",
    "responses": [
      {
        "questionId": "uuid",
        "transcriptionUrl": "s3://...",
        "transcriptionText": "...",
        "duration": 120
      }
    ]
  }
}
```

**Outgoing: analysis.completed**
```json
{
  "eventId": "uuid",
  "eventType": "analysis.completed",
  "timestamp": "2025-01-01T00:00:00Z",
  "data": {
    "interviewId": "uuid",
    "candidateId": "uuid",
    "overallScore": 85,
    "categoryScores": {
      "technicalSkills": 90,
      "communication": 80,
      "problemSolving": 85
    },
    "feedback": {
      "summary": "...",
      "strengths": ["..."],
      "improvements": ["..."]
    },
    "skillsExtracted": ["React", "TypeScript", "Node.js"]
  }
}
```

---

## Database Schema

### Tables

**analysis_results**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ analysis_results                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id                  UUID PRIMARY KEY                            â”‚
â”‚ interview_id        UUID NOT NULL (FK â†’ interviews)             â”‚
â”‚ candidate_id        UUID NOT NULL                               â”‚
â”‚ template_id         UUID NOT NULL                               â”‚
â”‚ overall_score       INTEGER (0-100)                             â”‚
â”‚ category_scores     JSONB                                       â”‚
â”‚ feedback            JSONB                                       â”‚
â”‚ skills_extracted    TEXT[]                                      â”‚
â”‚ raw_llm_response    TEXT                                        â”‚
â”‚ model_used          VARCHAR(100)                                â”‚
â”‚ tokens_used         INTEGER                                     â”‚
â”‚ processing_time_ms  INTEGER                                     â”‚
â”‚ status              ENUM('pending','processing','completed',    â”‚
â”‚                          'failed')                              â”‚
â”‚ error_message       TEXT                                        â”‚
â”‚ created_at          TIMESTAMP                                   â”‚
â”‚ updated_at          TIMESTAMP                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**job_embeddings (pgvector)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ job_embeddings                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id                  UUID PRIMARY KEY                            â”‚
â”‚ template_id         UUID NOT NULL (FK â†’ templates)              â”‚
â”‚ chunk_text          TEXT NOT NULL                               â”‚
â”‚ chunk_index         INTEGER                                     â”‚
â”‚ section_type        VARCHAR(50) (requirements, skills, etc)     â”‚
â”‚ embedding           VECTOR(1536)                                â”‚
â”‚ metadata            JSONB                                       â”‚
â”‚ created_at          TIMESTAMP                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- Index for vector similarity search
CREATE INDEX ON job_embeddings 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);
```

**question_analysis**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ question_analysis                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id                  UUID PRIMARY KEY                            â”‚
â”‚ analysis_result_id  UUID NOT NULL (FK â†’ analysis_results)       â”‚
â”‚ question_id         UUID NOT NULL                               â”‚
â”‚ transcription       TEXT                                        â”‚
â”‚ score               INTEGER (0-100)                             â”‚
â”‚ feedback            TEXT                                        â”‚
â”‚ keywords_detected   TEXT[]                                      â”‚
â”‚ sentiment           VARCHAR(20)                                 â”‚
â”‚ confidence          FLOAT                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## LLM Prompt Templates

### System Prompt (Interview Evaluator)

```
You are an expert technical interviewer and HR professional. 
Your task is to objectively evaluate candidate responses based on:
1. Job requirements provided as context
2. Technical accuracy of answers
3. Communication clarity
4. Problem-solving approach

Always provide:
- Numerical scores (0-100)
- Specific feedback with examples
- Actionable improvement suggestions

Be fair, unbiased, and focus on job-relevant criteria only.
```

### Evaluation Prompt Template

```
## Job Requirements Context
{retrieved_job_requirements}

## Interview Question
{question_text}

## Candidate Response (Transcribed)
{transcription}

## Evaluation Task
Analyze this response and provide:

1. **Score** (0-100): Based on relevance to job requirements
2. **Technical Assessment**: Accuracy of technical content
3. **Communication Score**: Clarity and structure
4. **Strengths**: What the candidate did well
5. **Improvements**: Specific areas to develop
6. **Keywords Detected**: Technical terms and skills mentioned

Output as JSON:
{
  "score": number,
  "technicalScore": number,
  "communicationScore": number,
  "strengths": string[],
  "improvements": string[],
  "keywordsDetected": string[],
  "detailedFeedback": string
}
```

---

## API Endpoints

### Analysis Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/analysis/:interviewId` | Get analysis results |
| `GET` | `/api/v1/analysis/:interviewId/questions` | Per-question breakdown |
| `POST` | `/api/v1/analysis/:interviewId/retry` | Retry failed analysis |
| `GET` | `/api/v1/candidates/:id/scores` | Candidate score history |
| `POST` | `/api/v1/compare` | Compare multiple candidates |

### Admin Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/admin/analysis/stats` | Processing statistics |
| `GET` | `/api/v1/admin/analysis/queue` | Queue status |
| `POST` | `/api/v1/admin/embeddings/rebuild` | Rebuild vector index |

---

## Processing Pipeline

### Sequence Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka  â”‚     â”‚ AI Svc  â”‚     â”‚pgvector â”‚     â”‚  Groq   â”‚     â”‚  Kafka  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚ interview.    â”‚               â”‚               â”‚               â”‚
     â”‚ completed     â”‚               â”‚               â”‚               â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚ Query similar â”‚               â”‚               â”‚
     â”‚               â”‚ job reqs      â”‚               â”‚               â”‚
     â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚               â”‚               â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚               â”‚               â”‚
     â”‚               â”‚ Top 5 chunks  â”‚               â”‚               â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚ Build prompt + analyze        â”‚               â”‚
     â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚               â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚               â”‚
     â”‚               â”‚ Structured response           â”‚               â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚ Save to DB    â”‚               â”‚               â”‚
     â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚               â”‚               â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
     â”‚               â”‚                               â”‚ analysis.     â”‚
     â”‚               â”‚                               â”‚ completed     â”‚
     â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
     â”‚               â”‚               â”‚               â”‚               â”‚
```

---

## Configuration

### Environment Variables

```bash
# Application
PORT=3007
NODE_ENV=development

# Database
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=ai_video_interview_analysis
DATABASE_USER=postgres
DATABASE_PASSWORD=postgres

# Groq API
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxx
GROQ_MODEL_PRIMARY=llama-3.3-70b-versatile
GROQ_MODEL_FAST=llama-3.1-8b-instant
GROQ_MAX_TOKENS=4096
GROQ_TEMPERATURE=0.3

# Embeddings (OpenAI or local)
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
EMBEDDING_MODEL=text-embedding-3-small

# Kafka
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=ai-analysis-service
KAFKA_GROUP_ID=ai-analysis-service-group

# Rate Limiting
GROQ_RATE_LIMIT_TOKENS=6000
GROQ_RATE_LIMIT_WINDOW_MS=60000

# Redis (for queue)
REDIS_HOST=localhost
REDIS_PORT=6379

# Observability
LOG_LEVEL=debug
LOKI_HOST=http://localhost:3100
JAEGER_ENDPOINT=http://localhost:14268/api/traces
```

---

## Error Handling

### Retry Strategy

| Error Type | Retry | Action |
|------------|-------|--------|
| Rate limit (429) | Yes (with backoff) | Queue and retry after reset |
| Timeout | Yes (3 attempts) | Exponential backoff |
| Invalid response | Yes (2 attempts) | Re-prompt with stricter format |
| API error (5xx) | Yes (3 attempts) | Exponential backoff |
| Validation error | No | Log and mark failed |

### Fallback Strategy

```
Primary Model (llama-3.3-70b) 
    â†“ (if rate limited)
Fast Model (llama-3.1-8b)
    â†“ (if both unavailable)
Queue for later processing
```

---

## Metrics & Monitoring

### Prometheus Metrics

```
ai_analysis_requests_total{status="success|failed"}
ai_analysis_processing_duration_seconds
ai_analysis_tokens_used_total
ai_analysis_queue_size
ai_analysis_groq_rate_limit_hits_total
ai_analysis_embedding_requests_total
```

### Health Check

```
GET /health

{
  "status": "ok",
  "groq": "connected",
  "database": "connected",
  "kafka": "connected",
  "queueSize": 5
}
```

---

## Dependencies

### Internal Services
- **Media Service** (3006) - Provides transcriptions
- **Interview Service** (3004) - Source of interview data
- **Notification Service** (3008) - Notifies HR on completion

### External Services
- **Groq API** - LLM inference
- **OpenAI API** - Text embeddings (optional)
- **PostgreSQL + pgvector** - Vector storage
- **Kafka** - Event streaming
- **Redis** - Rate limit queue

---

## Implementation Phases

### Phase 1: Foundation
- [ ] NestJS project setup with Clean Architecture
- [ ] Database schema + pgvector extension
- [ ] Groq API integration with rate limiting
- [ ] Basic Kafka consumer

### Phase 2: RAG Pipeline
- [ ] Embedding service integration
- [ ] Vector search implementation
- [ ] Prompt template system
- [ ] Structured output parsing

### Phase 3: Analysis Features
- [ ] Per-question analysis
- [ ] Overall interview scoring
- [ ] Skills extraction
- [ ] Candidate comparison

### Phase 4: Production Readiness
- [ ] Comprehensive error handling
- [ ] Metrics and monitoring
- [ ] Queue management
- [ ] Performance optimization

---

**Last Updated:** 2025-01-XX
