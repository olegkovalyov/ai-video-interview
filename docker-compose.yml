version: '3.8'

services:
  # PostgreSQL - Main database
  postgres:
    image: postgres:15-alpine
    container_name: ai-interview-postgres
    environment:
      POSTGRES_DB: ai_video_interview
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis - Cache and sessions
  redis:
    image: redis:7-alpine
    container_name: ai-interview-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # MinIO - S3-compatible object storage
  minio:
    image: minio/minio:latest
    container_name: ai-interview-minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Kafka - Message queue (for later phases)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: ai-interview-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    profiles:
      - kafka

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: ai-interview-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_HOST://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    profiles:
      - kafka

  # Kafka UI - Web interface for Kafka management
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: ai-interview-kafka-ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: ai-interview-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: true
    profiles:
      - kafka

  # Authentik - Authentication & Identity Provider
  authentik-postgresql:
    image: postgres:15-alpine
    container_name: ai-interview-authentik-postgres
    environment:
      POSTGRES_DB: authentik
      POSTGRES_USER: authentik
      POSTGRES_PASSWORD: authentik-password
    volumes:
      - authentik_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U authentik"]
      interval: 10s
      timeout: 5s
      retries: 5

  authentik-redis:
    image: redis:7-alpine
    container_name: ai-interview-authentik-redis
    command: redis-server --appendonly yes
    volumes:
      - authentik_redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  authentik-server:
    image: ghcr.io/goauthentik/server:2024.2.2
    container_name: ai-interview-authentik-server
    restart: unless-stopped
    command: server
    environment:
      AUTHENTIK_SECRET_KEY: "super-secret-key-change-in-production"
      AUTHENTIK_ERROR_REPORTING__ENABLED: "false"
      AUTHENTIK_DISABLE_UPDATE_CHECK: "true"
      AUTHENTIK_DISABLE_STARTUP_ANALYTICS: "true"
      AUTHENTIK_POSTGRESQL__HOST: authentik-postgresql
      AUTHENTIK_POSTGRESQL__USER: authentik
      AUTHENTIK_POSTGRESQL__NAME: authentik
      AUTHENTIK_POSTGRESQL__PASSWORD: authentik-password
      AUTHENTIK_REDIS__HOST: authentik-redis
    volumes:
      - authentik_media:/media
      - authentik_custom_templates:/templates
    ports:
      - "9443:9000"
    depends_on:
      - authentik-postgresql
      - authentik-redis

  authentik-worker:
    image: ghcr.io/goauthentik/server:2024.2.2
    container_name: ai-interview-authentik-worker
    restart: unless-stopped
    command: worker
    environment:
      AUTHENTIK_SECRET_KEY: "super-secret-key-change-in-production"
      AUTHENTIK_ERROR_REPORTING__ENABLED: "false"
      AUTHENTIK_DISABLE_UPDATE_CHECK: "true"
      AUTHENTIK_DISABLE_STARTUP_ANALYTICS: "true"
      AUTHENTIK_POSTGRESQL__HOST: authentik-postgresql
      AUTHENTIK_POSTGRESQL__USER: authentik
      AUTHENTIK_POSTGRESQL__NAME: authentik
      AUTHENTIK_POSTGRESQL__PASSWORD: authentik-password
      AUTHENTIK_REDIS__HOST: authentik-redis
    volumes:
      - authentik_media:/media
      - authentik_custom_templates:/templates
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - authentik-postgresql
      - authentik-redis

  # ClickHouse - Analytics database (for later phases)
  clickhouse:
    image: clickhouse/clickhouse-server:23.8-alpine
    container_name: ai-interview-clickhouse
    ports:
      - "8123:8123"
      - "9009:9000"
    environment:
      CLICKHOUSE_DB: analytics
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ""
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    profiles:
      - analytics

volumes:
  postgres_data:
  redis_data:
  minio_data:
  zookeeper_data:
  kafka_data:
  clickhouse_data:
  authentik_postgres_data:
  authentik_redis_data:
  authentik_media:
  authentik_custom_templates:

networks:
  default:
    name: ai-interview-network
